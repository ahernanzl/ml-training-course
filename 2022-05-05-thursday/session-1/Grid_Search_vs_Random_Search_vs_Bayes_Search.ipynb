{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid Search vs Random Search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search vs Random Search\n",
        "From [Scikit-learn documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)\n",
        "\n",
        "This example evaluates the cross-validated grid search and the cross-validated random search of the parameter space for a small classifier."
      ],
      "metadata": {
        "id": "KovZ83Sez91E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5hP0ex5aQu8",
        "outputId": "c6f88dea-e738-4d50-8c02-3c61000611f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NW4LSqYmy1MU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "import scipy.stats as stats\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from skopt import BayesSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data & Define Classifier\n",
        "\n",
        "Linear [Stochastic Gradient Descent Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) from scikit-learn with a [Hinge loss](https://en.wikipedia.org/wiki/Hinge_loss) for maximum-margin classifiers and [elastic net regularization](https://en.wikipedia.org/wiki/Elastic_net_regularization)."
      ],
      "metadata": {
        "id": "d-IdFtI80W2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get some data\n",
        "X, y = load_digits(return_X_y=True, n_class=3)\n",
        "\n",
        "# build a classifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)"
      ],
      "metadata": {
        "id": "HJ21skpOy3iA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report Utility"
      ],
      "metadata": {
        "id": "WZWEW00a0hEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\n",
        "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                    results[\"mean_test_score\"][candidate],\n",
        "                    results[\"std_test_score\"][candidate],\n",
        "                )\n",
        "            )\n",
        "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
        "            print(\"\")"
      ],
      "metadata": {
        "id": "dd9o5evwy8kg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we optimize\n",
        "\n",
        "Define the parameter distribution for `average`, `l1_ratio`, and `alpha` in the SGDCLassifier. \n",
        "\n",
        "- `average`: Whether to comput average weights over computations\n",
        "- `l1_ratio`: ElasticNet mixing parameter, balancing L1 norm and L2 norm regularization.\n",
        "- `alpha`: Strength of regularization\n",
        "\n",
        "We set `n_iter` to `15` for a relatively small budget.\n",
        "\n",
        "## Randomized Search\n",
        "\n",
        "- Opportunistic search\n",
        "- Budget independent of No. parameters\n",
        "- Adding Parameters not Inefficient\n",
        "- Search continues after minimum\n",
        "- Possible to miss optimal parameters due to random sampling without direction"
      ],
      "metadata": {
        "id": "C3YQxLOc0oaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": stats.uniform(0, 1),\n",
        "    \"alpha\": loguniform(1e-2, 1e0),\n",
        "}\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 15\n",
        "random_search = RandomizedSearchCV(\n",
        "    clf, param_distributions=param_dist, n_iter=n_iter_search,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "MWvwKhqKy_Qk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "random_search.fit(X, y)\n",
        "print(\n",
        "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
        "    % ((time() - start), n_iter_search)\n",
        ")\n",
        "report(random_search.cv_results_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocF1SCBEzDb5",
        "outputId": "25c08280-dfb2-4a0e-cb2f-a39a013ffa05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomizedSearchCV took 0.80 seconds for 15 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.989 (std: 0.011)\n",
            "Parameters: {'alpha': 0.16738085788752124, 'average': False, 'l1_ratio': 0.04666566321361543}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.981 (std: 0.020)\n",
            "Parameters: {'alpha': 0.010994335574766197, 'average': False, 'l1_ratio': 0.7219987722668247}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.980 (std: 0.016)\n",
            "Parameters: {'alpha': 0.023270677083837798, 'average': False, 'l1_ratio': 0.6116531604882809}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Search\n",
        "\n",
        "This discretizes the search space from the boundaries used in the random search to obtain a grid to search.\n",
        "\n",
        "- Exhaustive Search\n",
        "- Every Combination is Evaluated\n",
        "- Combinatoric Explosion of Evals\n",
        "- Iterating beyond global minimum to evaluate all gridpoints\n",
        "- Possible to miss optimal parameters because explicit values are provided"
      ],
      "metadata": {
        "id": "-2atBeyR6q5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
        "    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n",
        "}\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\n",
        "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
        ")\n",
        "report(grid_search.cv_results_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAERY3VTzEf2",
        "outputId": "44329c76-3fb8-463b-9fe0-64d808e571eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV took 5.03 seconds for 60 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.994 (std: 0.007)\n",
            "Parameters: {'alpha': 0.1, 'average': False, 'l1_ratio': 0.2222222222222222}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.993 (std: 0.007)\n",
            "Parameters: {'alpha': 0.01, 'average': False, 'l1_ratio': 0.1111111111111111}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.993 (std: 0.007)\n",
            "Parameters: {'alpha': 0.01, 'average': False, 'l1_ratio': 0.2222222222222222}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.993 (std: 0.004)\n",
            "Parameters: {'alpha': 0.1, 'average': False, 'l1_ratio': 0.6666666666666666}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization\n",
        "\n",
        "This imports the `scikit-optimize` package to compare a Bayesian Search for optimal parameters. \n",
        "\n",
        "This uses the same boundaries as the random search and `15` iterations. \n",
        "\n",
        "- Search based on former parameters\n",
        "- Bayesian optimization\n",
        "- Converges to a minimum\n",
        "- Adding parameters adds complexity\n",
        "- Unimportant parameters complicate optimization significantly\n",
        "\n",
        "\n",
        "**Note:** that the parameter grid is defined slightly different, since the Bayeasian search has an internal implementation for `uniform` and `log-uniform` sampling."
      ],
      "metadata": {
        "id": "BI-CV14I63Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": (0, 1, 'uniform'),\n",
        "    \"alpha\": (1e-2, 1e0, 'log-uniform'),\n",
        "}\n",
        "\n",
        "# run grid search\n",
        "bayes_search = BayesSearchCV(clf, param_grid, n_iter=n_iter_search)\n",
        "start = time()\n",
        "bayes_search.fit(X, y)\n",
        "\n",
        "print(\n",
        "    \"BayesSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "    % (time() - start, len(bayes_search.cv_results_[\"params\"]))\n",
        ")\n",
        "report(bayes_search.cv_results_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igMKy9alzUEQ",
        "outputId": "155f7266-ee2f-4ebc-c596-d0b81c58f77b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BayesSearchCV took 11.99 seconds for 15 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.993 (std: 0.009)\n",
            "Parameters: OrderedDict([('alpha', 0.5228830309877981), ('average', False), ('l1_ratio', 0)])\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.991 (std: 0.006)\n",
            "Parameters: OrderedDict([('alpha', 0.031583415023487306), ('average', False), ('l1_ratio', 0)])\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.985 (std: 0.007)\n",
            "Parameters: OrderedDict([('alpha', 0.4421444661338732), ('average', False), ('l1_ratio', 0)])\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.985 (std: 0.010)\n",
            "Parameters: OrderedDict([('alpha', 0.1169672970533936), ('average', False), ('l1_ratio', 0)])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GLs-3mzya6YE"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}